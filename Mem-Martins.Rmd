---
title: "Mem-Martins"
author: "helder"
date: "`r Sys.Date()`"
output: pdf_document
---

## Mem-Martins {-}

```{r , include=FALSE}
# Ihavo (SIC)
y <- qualityAR03 %>% filter(Location=="Mem-Martins")
```

```{r, echo=FALSE, include=FALSE}
lambda <- y %>%
  features(Ozone, features = guerrero) %>%
  pull(lambda_guerrero)
#caption_tex = paste0("Difference h=24 Box-Cox Transformation $\\lambda$ = ", round(lambda,2))
```

The Mem-Martins series plot is in figure \@ref(fig:mem-ts). Because of  seasonality present a seasonal difference was applied and a Box-Cox transformation also was used to improve stability in the variance.

The Unit root tests as resumed in table \ref{tab:mem-esth-stationary} where not considered relevant.

```{r mem-ts, fig.pos="!h", out.extra = "", fig.cap=paste(y$Location[1], " - Time series"), fig.dim=c(7, 3), include=TRUE}
y %>% gg_tsdisplay(Ozone, plot_type = "partial", lag_max = 200)
```

```{r mem-esth-stationary, include=TRUE}
adf <- function(x, ...) {
  out <- tseries::adf.test(x, k = 1)
  c(adf_stat = unname(out$statistic), adf_pvalue = out$p.value)
}
# tseries::adf.test(box_cox(y$Ozone, lambda), k=1)
kbl(y %>%
      mutate(Ozone = box_cox(Ozone, lambda)) %>%
      features(Ozone, 
               list(unitroot_kpss, adf, unitroot_ndiffs, ~ unitroot_nsdiffs(., .period = 24))),
    caption = paste(y$Location[1], " - Unit root tests and suggested number of differences"),
    booktabs = T) %>% 
  kable_styling(latex_options = "hold_position")
```

Looking at the seasonal difference series (h=24) in figure \@ref(fig:mem-diffplot), it shows no trend, and the ACF and PACF plots look typical of a stationary series (no further differentiate). In the ACF there is one seasonal significant correlation at lag 24 meaning that an SMA(2) component model will be used. In the the first lags only 2 are significant in the PACF and a AR(2) component will be considered. The final predicted model is of the form SARIMA(2,0,0)(0,1,1)[24].

```{r mem-diffplot, fig.pos="!h", out.extra = "", fig.cap=paste(y$Location[1], " - Difference h=24 Box-Cox Transformation $\\lambda$ = ", round(lambda,2)), fig.dim=c(7, 4), include=TRUE}
y %>%
  gg_tsdisplay(difference(box_cox(Ozone, lambda), lag = 24), plot_type = "partial", lag_max = 200) +
  labs(y = "")
```

```{r , include=FALSE}
#  [1] "Location"     "sarima000101" "sarima100101" "sarima001101" "sarima101101" "sarima201101"
#  [7] "sarima102101" "sarima202101" "sarima000012" "sarima100012" "sarima200012" "sarima101012"
# [13] "sarima201012"
#fits <- readRDS("models/Laranjeiro-Alamada_fit_s012.rds") %>% select(-c(2, 3, 4, 5, 6, 7, 8, 9))
fits <- readRDS("models/mem-martins_fit_s011.rds")
fit <- fits %>% select(Location, sarima301011)
```

Again the predicted model lead to correlated residuals, and variations where tested, as resumed in table \@ref(tab:mem-model-comparison).
Only a model with more order would pass the non correlated residuals test, so the decision was to keep model `r format(fit %>% pull(2))`. Diagnostic plots in figure \@ref(fig:mem-fit-resid-plot), prove the residuals have similar characteristics as previous examples to be considered valid (no correlation, and shape similar to normal distribution).

```{r, include=FALSE}
plot.box.ljung <- function (
    z, k = 10, main = "Ljung-Box test (k)", ylab = "p-value"
) {
  p <- rep(NA, k)

  for (i in 1:k) {
    p[i] <- Box.test(z, i, type = "Ljung-Box")$p.value
  }

  ggplot(as_tibble(p), aes(x=1:k, y=p)) +
    geom_bar(stat='identity', width =0.05) +
    geom_point() + ylim(0,1) + ylab(ylab) +
    geom_abline(intercept = .05, slope = 0, lty = 3) +
    ggtitle(main)
}
```

```{r mem-fit-resid-plot, fig.pos="H", out.extra = "", fig.cap=paste(y$Location[1], format(fit %>% pull(2)), "standardized residuals diagnostic plots"), fig.dim=c(7, 8), include=TRUE}
m <- fit %>% augment() %>% mutate( .innov = scale(.innov) )

p1 <- m %>% autoplot(.innov)
p2 <- m %>% ACF(.innov, lag_max = 60) %>% autoplot() + ylim(-0.1, 0.3)
p3 <- m %>% PACF(.innov, lag_max = 60) %>% autoplot() + ylim(-0.1, 0.3)
p4 <- m %>%  gghistogram(x=".innov", bins = 150)
p5 <- plot.box.ljung(m %>% pull(.innov), k=10)
p6 <- ggqqplot(m,".innov", title = "QQ plot")
p7 <- ggplot(m, aes(x = .fitted, y = .innov)) +
        geom_point()

(p1) / (p2 + p3) / (p4 + p5) / (p6 + p7)
rm(m)
```

```{r mem-model-comparison, include=TRUE}
kbl(fits %>% 
      pivot_longer(!Location, names_to = "Model name",
                     values_to = "Orders") %>%
      mutate("Model" = format(Orders)) %>%
      glance() %>%
      select(Location, Model, AIC, AICc, BIC),
    format = "latex", 
    caption = paste(y$Location[1], "model comparison"), 
    booktabs = T) %>% 
  kable_styling(latex_options = "hold_position")
```

```{r, include=FALSE, eval=FALSE}
fit <- fits %>% select(Location, sarima201012)
```

```{r mem-fit-resid-plot0, fig.pos="H", out.extra = "", fig.cap=paste(y$Location[1], format(fit %>% pull(2)), "standardized residuals diagnostic plots"), fig.dim=c(7, 8), include=TRUE, eval=FALSE}
m <- fit %>% augment() %>% mutate( .innov = scale(.innov) )

p1 <- m %>% autoplot(.innov)
p2 <- m %>% ACF(.innov, lag_max = 100) %>% autoplot() + ylim(-0.1, 0.2)
p3 <- m %>% PACF(.innov, lag_max = 100) %>% autoplot() + ylim(-0.1, 0.2)
p4 <- m %>%  gghistogram(x=".innov", bins = 150)
p5 <- plot.box.ljung(m %>% pull(.innov), k=10)
p6 <- ggqqplot(m,".innov", title = "QQ plot")
p7 <- ggplot(m, aes(x = .fitted, y = .innov)) +
        geom_point()

(p1) / (p2 + p3) / (p4 + p5) / (p6 + p7)
rm(m)
```

The coefficients are statistical significant, as resumed in table \@ref(tab:mem-coef), all p-values of the t-test (H0: coefficient is zero) lead to rejecting the null hypothesis.

```{r mem-coef, include=TRUE}
kbl(fit %>% coef(), 
    format = "latex", 
    caption = paste(y$Location[1], format(fit %>% pull(2)), "Coefficient statistics"), 
    booktabs = T) %>% 
  kable_styling(latex_options = "hold_position")
```

Model forecasts were obtained in the table \@ref(tab:mem-forecast-tab), and figure \@ref(fig:mem-forecast-plot). Although the mean forecast values seem to be reasonable the confidence interval are wide. Also notice that the innovation process have a high variance. The cross-validation (horizon=5) on the last month again show some higher variance than the sample path.

```{r mem-forecast-tab, include=TRUE}
f <- fit %>% forecast(h=5)

kbl(f %>%  hilo(level = c(95)) %>% select(-c(1,2)),
             caption = paste(y$Location[1], format(fit %>% pull(2)), "forecast 5 periods ahead (95\\% CI)"),
             booktabs = T) %>%
  kable_styling(latex_options = "hold_position")
```

```{r mem-forecast-plot, fig.pos="!h", out.extra = "", fig.cap=paste(y$Location[1], format(fit %>% pull(2)), "forecasts"), fig.dim=c(6, 2), include=TRUE}
f %>% 
  autoplot(y %>%
              filter(between(index,as_datetime("2020-12-15"), as_datetime("2021-01-01"))),
            level = 95,
            alpha = 0.5)
```

```{r mem-cv, include=FALSE}
training <- y %>% filter(month(index) <= 11)
test <- y %>% filter(month(index) > 11)

train_fit <- training %>%
  model(
    sarimacv = ARIMA(box_cox(Ozone, lambda) ~ 0 + pdq(3, 0, 1) + PDQ(0, 1, 1, period=24))
  )

test_refit <- train_fit %>% refit(test)

# fits5 <- test_refit %>% fitted(h = 5)
# saveRDS(fits5, file = "models/mem-martins_cv_fits5.rds")
# Load
fits5 <- readRDS("models/mem-martins_cv_fits5.rds")

#fits1 <- test_refit %>% fitted(h = 1)
```

```{r mem-cv-accuracy-tab}
kbl(bind_rows(
      fit %>% accuracy() %>% select(RMSE, MAE),
      test_refit %>% accuracy() %>% select(RMSE, MAE)
      ) %>% 
      add_column(Type = c("Series", "CV")) %>% 
      select(3, 1, 2),
    caption = paste(y$Location[1], format(fit %>% pull(2)), "Series and Crossvalidation Accuracy"),
    booktabs = T) %>%
  kable_styling(latex_options = "hold_position")
```

```{r mem-cv-plot, fig.pos="!h", out.extra = "", fig.cap=paste(y$Location[1], format(test_refit %>% pull(2)), "crossvalidation forecasts"), fig.dim=c(6, 2), include=TRUE}
test %>%
  autoplot(Ozone) +
  autolayer(fits5, .fitted, col = "#D55E00")
```

